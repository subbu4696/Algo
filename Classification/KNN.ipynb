{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "https://towardsdatascience.com/tree-algorithms-explained-ball-tree-algorithm-vs-kd-tree-vs-brute-force-9746debcd940\n",
    "\n",
    "https://medium.com/analytics-vidhya/why-is-scaling-required-in-knn-and-k-means-8129e4d88ed7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN- K nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Knn is a lazy learner . it  take constant time in train stage , it only takes time in predicting stage of new data point.\n",
    "- lower k value overfits and higher k value underfits .\n",
    "- its sensitive to outliers\n",
    "- no functional form of knn\n",
    "- out put is in probability of classes according to votes in n neighbours\n",
    "- global method and local method\n",
    "    - assigns weights to all the points \n",
    "    -  assigns weights to only nearest neighbours\n",
    "- wighted knn works well with noisy data\n",
    "- smoothen decision boundary: weighted knn or increase k value\n",
    "- with increase in cardinality - knn deteriorates its performance\n",
    "- memory indexing problem with weighted knn?\n",
    "- latency issues as predictition time increases with train data\n",
    "- its a memory based learner\n",
    "- optimal k value chosen  by  using cross validation where the error value is less.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- distance parms: minkowski,manhattan,eucledian\n",
    "- p : manhattan if 1 eucledian if 2 otherthan 1,2 its minkowski\n",
    "- algorithm used to find nearest neighbour tree - kd tree , ball tree, brute force\n",
    "- weights{uniform or distance or callable function} : in the k nearest neighbours dominant class has more distance when comppared to one with nearer distance which is actual class to the new point , weights can be used to add more importance to nearest points.\n",
    "- leaf size : is given to kd tree , ball tree which memorizes the points in the form of tree structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
